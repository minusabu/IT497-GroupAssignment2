
```{r, message=FALSE,warning=FALSE}
##load the packages

library("twitteR")
library("wordcloud")
library("tm")
library("ggplot2")
library("reshape2")
```

```{r, message=FALSE,warning=FALSE}
##read in the data from the text files

microsoftDay1<- read.table(file = "microsoft1.txt", skipNul = TRUE )
microsoftDay2<- read.table(file = "microsoft2.txt", skipNul = TRUE)
microsoftDay3 <- read.table( file = "microsoft3.txt", skipNul = TRUE)
microsoftDay4 <- read.table( file = "microsoft4.txt", skipNul = TRUE) 
microsoftDay5<- read.table( file = "microsoft5.txt", skipNul = TRUE) 
```

```{r}
##load opinion lexicon

pos <-scan("positive-words.txt",what="character",comment.char=";")
neg <-scan("negative-words.txt",what="character",comment.char=";")
```

Day 1
```{r}

microsoftTweets1.corpus <- Corpus(VectorSource(microsoftDay1$text))

## clean up
microsoftTweets1.corpus <- tm_map(microsoftTweets1.corpus, tolower)
microsoftTweets1.corpus <- tm_map(microsoftTweets1.corpus, removePunctuation)
microsoftTweets1.corpus <- tm_map(microsoftTweets1.corpus, function(x) removeWords(x,stopwords()))

## split the tweets in the corpus up into individual words
## lapply iterates over each element in the corpus
## and applies the strsplit function
## the splitting argument is the 3rd in the lapply function
## and is splitting on white space.
corpus.split.day1 <- lapply(microsoftTweets1.corpus,strsplit,"\\s+")

## find matches for the individual words in the two lexicons
## lapply again, x takes on an element in the corpus
## at each iteration
matches.day1 <- lapply(corpus.split.day1,function(x) {

  match.pos.day1 <- match(x[[1]],pos)

  match.neg.day1 <- match(x[[1]],neg)

## return the length of each match vector, non-na  
  list(length(which(!is.na(match.pos.day1))),length(which(!is.na(match.neg.day1))))

})

## turn the matches into a matrix
## one column for positive, one for negative
match.matrix.day1 <- matrix(unlist(matches.day1),nrow=length(matches.day1),ncol=2,byrow=T)
 
simple.microsoft.sentiment.day1 <- match.matrix.day1[,1] - match.matrix.day1[,2]

length(microsoftTweets1)
hist(simple.microsoft.sentiment.day1)
```


Day 2
```{r, message=FALSE,warning=FALSE}

## clean up
microsoftTweets2.corpus <- Corpus(VectorSource(microsoftDay2$text))
microsoftTweets2.corpus <- tm_map(microsoftTweets2.corpus, tolower)
microsoftTweets2.corpus <- tm_map(microsoftTweets2.corpus, removePunctuation)
microsoftTweets2.corpus <- tm_map(microsoftTweets2.corpus, function(x) removeWords(x,stopwords()))

## split the tweets in the corpus up into individual words
## lapply iterates over each element in the corpus
## and applies the strsplit function
## the splitting argument is the 3rd in the lapply function
## and is splitting on white space.
corpus.split.day2 <- lapply(microsoftTweets2.corpus,strsplit,"\\s+")

## find matches for the individual words in the two lexicons
## lapply again, x takes on an element in the corpus
## at each iteration

matches.day2 <- lapply(corpus.split.day2,function(x) {

  match.pos.day2 <- match(x[[1]],pos)

  match.neg.day2 <- match(x[[1]],neg)

  
  list(length(which(!is.na(match.pos.day2))),length(which(!is.na(match.neg.day2))))

})

## turn the matches into a matrix
## one column for positive, one for negative
match.matrix.day2 <- matrix(unlist(matches.day2),nrow=length(matches.day2),ncol=2,byrow=T)
 
simple.microsoft.sentiment.day2 <- match.matrix.day2[,1] - match.matrix.day2[,2]

length(microsoftTweets2)
hist(simple.microsoft.sentiment.day2)
```
 
Day 3
```{r, message=FALSE,warning=FALSE}

## clean up
microsoftTweets3.corpus <- Corpus(VectorSource(microsoftDay3$text))
microsoftTweets3.corpus <- tm_map(microsoftTweets3.corpus, tolower)
microsoftTweets3.corpus <- tm_map(microsoftTweets3.corpus, removePunctuation)
microsoftTweets3.corpus <- tm_map(microsoftTweets3.corpus, function(x) removeWords(x,stopwords()))

## split the tweets in the corpus up into individual words
## lapply iterates over each element in the corpus
## and applies the strsplit function
## the splitting argument is the 3rd in the lapply function
## and is splitting on white space.
corpus.split.day3 <- lapply(microsoftTweets3.corpus,strsplit,"\\s+")

## find matches for the individual words in the two lexicons
## lapply again, x takes on an element in the corpus
## at each iteration
matches.day3 <- lapply(corpus.split.day3,function(x) {

  match.pos.day3 <- match(x[[1]],pos)

  match.neg.day3 <- match(x[[1]],neg)

  
  list(length(which(!is.na(match.pos.day3))),length(which(!is.na(match.neg.day3))))

})

## turn the matches into a matrix
## one column for positive, one for negative
match.matrix.day3 <- matrix(unlist(matches.day3),nrow=length(matches.day3),ncol=2,byrow=T)
 
simple.microsoft.sentiment.day3 <- match.matrix.day3[,1] - match.matrix.day3[,2]

hist(simple.microsoft.sentiment.day3)
```


Day 4
```{r, message=FALSE,warning=FALSE}

## clean up
microsoftTweets4.corpus <- Corpus(VectorSource(microsoftDay4$text))
microsoftTweets4.corpus <- tm_map(microsoftTweets4.corpus, tolower)
microsoftTweets4.corpus <- tm_map(microsoftTweets4.corpus, removePunctuation)
microsoftTweets4.corpus <- tm_map(microsoftTweets4.corpus, function(x) removeWords(x,stopwords()))

## split the tweets in the corpus up into individual words
## lapply iterates over each element in the corpus
## and applies the strsplit function
## the splitting argument is the 3rd in the lapply function
## and is splitting on white space.
corpus.split.day4 <- lapply(microsoftTweets4.corpus,strsplit,"\\s+")

## find matches for the individual words in the two lexicons
## lapply again, x takes on an element in the corpus
## at each iteration
matches.day4 <- lapply(corpus.split.day4,function(x) {

  match.pos.day4 <- match(x[[1]],pos)

  match.neg.day4 <- match(x[[1]],neg)

  
  list(length(which(!is.na(match.pos.day4))),length(which(!is.na(match.neg.day4))))

})
## turn the matches into a matrix
## one column for positive, one for negative
match.matrix.day4 <- matrix(unlist(matches.day4),nrow=length(matches.day4),ncol=2,byrow=T)
 
simple.microsoft.sentiment.day4 <- match.matrix.day4[,1] - match.matrix.day4[,2]

hist(simple.microsoft.sentiment.day4)
```

Day 5
```{r, message=FALSE,warning=FALSE}

## clean up
microsoftTweets5.corpus <- Corpus(VectorSource(microsoftDay5$text))
microsoftTweets5.corpus <- tm_map(microsoftTweets5.corpus, tolower)
microsoftTweets5.corpus <- tm_map(microsoftTweets5.corpus, removePunctuation)
microsoftTweets5.corpus <- tm_map(microsoftTweets5.corpus, function(x) removeWords(x,stopwords()))

## split the tweets in the corpus up into individual words
## lapply iterates over each element in the corpus
## and applies the strsplit function
## the splitting argument is the 3rd in the lapply function
## and is splitting on white space.
corpus.split.day5 <- lapply(microsoftTweets5.corpus,strsplit,"\\s+")

## find matches for the individual words in the two lexicons
## lapply again, x takes on an element in the corpus
## at each iteration
matches.day5 <- lapply(corpus.split.day5,function(x) {

  match.pos.day5 <- match(x[[1]],pos)

  match.neg.day5 <- match(x[[1]],neg)

  
  list(length(which(!is.na(match.pos.day5))),length(which(!is.na(match.neg.day5))))

})
## turn the matches into a matrix
## one column for positive, one for negative
match.matrix.day5 <- matrix(unlist(matches.day5),nrow=length(matches.day5),ncol=2,byrow=T)
 
simple.microsoft.sentiment.day5 <- match.matrix.day5[,1] - match.matrix.day5[,2]

hist(simple.microsoft.sentiment.day5)
```


 
```{r, message=FALSE,warning=FALSE}
##Plotting the comparison graph

##obtain the sum of the sentiment numbers
microsoft.sentiment.day1<-sum(simple.microsoft.sentiment.day1)
microsoft.sentiment.day2<-sum(simple.microsoft.sentiment.day2)
microsoft.sentiment.day3<-sum(simple.microsoft.sentiment.day3)
microsoft.sentiment.day4<-sum(simple.microsoft.sentiment.day4)
microsoft.sentiment.day5<-sum(simple.microsoft.sentiment.day5)

##obtain overall sentiment level
microsoft.sentimentlevel.day1<-ifelse(microsoft.sentiment.day1>0, 1, -1)
microsoft.sentimentlevel.day2<-ifelse(microsoft.sentiment.day2>0, 1, -1)
microsoft.sentimentlevel.day3<-ifelse(microsoft.sentiment.day3>0, 1, -1)
microsoft.sentimentlevel.day4<-ifelse(microsoft.sentiment.day4>0, 1, -1)
microsoft.sentimentlevel.day5<-ifelse(microsoft.sentiment.day5>0, 1, -1)

#create a dataframe with all sentiment levels
complete.microsoft.sentimentlevel<-c(microsoft.sentimentlevel.day1,microsoft.sentimentlevel.day2,microsoft.sentimentlevel.day3,microsoft.sentimentlevel.day4,microsoft.sentimentlevel.day5)

##create a dataframe of stock gains or losses at close
stock<-c(-1, -1, -1, -1, -1)

day<-c("1", "2", "3", "4", "5")

#melt the data together
microsoft.sentiment.final<-data.frame(day,complete.microsoft.sentimentlevel, stock)
molten.microsoft.sentiment.final<-melt(microsoft.sentiment.final, id.vars="day")

##plot the combined data using a comparison chart
ggplot(molten.microsoft.sentiment.final, aes(day, value, fill = variable)) +
  geom_bar(stat="identity", position=position_dodge())
```
The graph depicts that Twitter can predict stock price movements. Each day, aside from day 2, there was negative sentiment towards Microsoft, and each day the stock closed at a loss. Twitter can give investors who use technology an advantage over those who do not. In the investing world, those who receive news that may impact stock prices the fastest can often benefit financially or minimize their losses. According to O'Connell,"Twitter is a beehive of social media activity, with 645 million active users and 135,000 brand new users every day." With that many users actively tweeting up to the minute updates, it is easy to conduct social sentiment analysis, and therefore, easy to predict stock movements. Of course, this information is most valuable to traders and investors, and Twitter has reaped the profits of this clientele. Clients who receive sentiment analysis scores can then determine whether speculation around the stock was considered good or bad, and they can then make trades based upon the sentiment score.  Twitter received $47.5 million from its data licensing services in 2011. Despite these benefits, there are potential risks and challenges. Because of the vast number of users, much of the data mined from Twitter may not even be relevant. Despite millions of tweets, only a handful might carry useful information pertaining to stocks. Furthermore, although Twitter can be a good source for up to the minute information, some of that information may be inaccurrate. Twitter can be easily manipulated, and one false tweet can cause a significant change in stock prices. For example, Leinweiber states "the Associated Press sent out a Tweet based on bogus information that two bombs had gone off at the White House, injuring the President. The Dow Jones Industrial Average dropped 145 points in a minute, recovering by 1:10." In this case, sentiment analysis did its job and alerted investors to negative chatter, but that chatter proved to be false. Or, in the case of day 2, sentiment levels and stock prices may be the inverse of each other. In conclusion, sentiment analysis can predict stock prices based upon chatter, but whether that chatter is relevant or accurrate is up to the investor to decide.

References: 
http://www.forbes.com/sites/davidleinweber/2013/04/24/so-much-for-fund-mining-twitter-sentiment-for-picking-stocks-but-ok-at-the-sec/
http://www.investopedia.com/articles/markets/031814/can-tweets-and-facebook-posts-predict-stock-behavior-and-rt-if-you-think-so.asp